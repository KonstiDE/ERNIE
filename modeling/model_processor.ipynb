{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Load model created by analyse_docs(...)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b4827133d378744"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import fasttext\n",
    "import pickle as pkl\n",
    "import shutup\n",
    "\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import hf_hub_download\n",
    "from bertopic import BERTopic\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "shutup.please()\n",
    "\n",
    "base_path = \"/home/s371513/ernie/\"\n",
    "out_path = \"/data/konsti_data/out/noto/\"\n",
    "\n",
    "topic_model = BERTopic.load(os.path.join(base_path, \"model\"))\n",
    "model_path = hf_hub_download(repo_id=\"facebook/fasttext-language-identification\", filename=\"model.bin\")\n",
    "model = fasttext.load_model(model_path)\n",
    "\n",
    "tmodel = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T06:30:41.195886100Z",
     "start_time": "2024-02-28T06:30:33.610720500Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Label Topics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f5a764be83b8ec8"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "custom_topics = {}\n",
    "\n",
    "for i in range(len(topic_model.get_topic_info())):\n",
    "    s = \"\"\n",
    "    \n",
    "    for tup in topic_model.get_topic(i):    \n",
    "        try:\n",
    "            impact_factor = float(tup[1])\n",
    "            topic_keyword = tup[0]\n",
    "        except Exception as _:\n",
    "            impact_factor = float(tup[0])\n",
    "            topic_keyword = tup[1]\n",
    "            \n",
    "        encoded_hi = tokenizer(topic_keyword, return_tensors=\"pt\")\n",
    "        generated_tokens = tmodel.generate(**encoded_hi)\n",
    "        token = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        s += str(token) + \" [\" + str(impact_factor) + \"]\\n\"\n",
    "    \n",
    "    topic = input(\"----------------------------\\nTopics already created: \\n{}\\n----------Topic {}----------\\n{}----------------------------\".format(set(custom_topics.values()), str(i), s))\n",
    "        \n",
    "    custom_topics[i] = topic\n",
    "\n",
    "with open(os.path.join(base_path, \"custom_topics.pkl\"), \"wb+\") as f:\n",
    "    pkl.dump(custom_topics, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T06:24:31.369384900Z",
     "start_time": "2024-02-28T05:51:48.103006Z"
    }
   },
   "id": "ce6edb44c0b1dfa7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
